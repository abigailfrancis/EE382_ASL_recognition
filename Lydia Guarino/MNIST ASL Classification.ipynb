{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aging-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import math\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# initialize data frames for import\n",
    "asl_alpha_df = pd.DataFrame({\"images\":[], \"label\":[]})\n",
    "asl_digits_df = pd.DataFrame({\"images\":[], \"label\":[]})\n",
    "lg_df = pd.DataFrame({\"images\":[], \"label\":[]})\n",
    "\n",
    "# import paths\n",
    "asl_path = '../raw data/asl_dataset/'\n",
    "lg_path = '../raw data/asl_lg/'\n",
    "asl_folders = glob(asl_path+'/*')\n",
    "lg_folders = glob(lg_path+'/*')\n",
    "\n",
    "# class set variations\n",
    "letter_classes = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"]\n",
    "all_classes = [i for i in \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"]\n",
    "\n",
    "# import asl data\n",
    "\n",
    "def import_data(df, folders, isDigits):\n",
    "    for path in folders:\n",
    "        img_path = glob(path+'/*')\n",
    "        _,label = os.path.split(path)\n",
    "        files = os.listdir(path)\n",
    "        for filename in files:\n",
    "            im = cv.imread(path+'/'+filename, 64).flatten() # 64 is for IMREAD_REDUCED_GRAYSCALE_8 (grayscale, 1/8th)\n",
    "            if (path[-1].isdigit() == isDigits):\n",
    "                data = pd.DataFrame({\"images\":[im], \"label\":[label]})\n",
    "                df = df.append(data, ignore_index = True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "instructional-count",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved data in ./train_test/base\n",
      "saved data in ./train_test/combo\n",
      "saved data in ./train_test/alphalg\n"
     ]
    }
   ],
   "source": [
    "asl_alpha_df = import_data(asl_alpha_df, asl_folders, False)\n",
    "asl_alpha_df.to_csv('./dataframes/asl_alpha_df.csv')\n",
    "\n",
    "asl_digits_df = import_data(asl_digits_df, asl_folders, True)\n",
    "asl_digits_df.to_csv('./dataframes/asl_digits_df.csv')\n",
    "\n",
    "lg_df = import_data(lg_df, lg_folders, False)\n",
    "lg_df.to_csv('./dataframes/lg_df.csv')\n",
    "\n",
    "asl_alpha_digits_df = asl_digits_df.append(asl_alpha_df, ignore_index = True)\n",
    "asl_alpha_digits_df.to_csv('./dataframes/asl_alpha_digits_df.csv')\n",
    "\n",
    "asl_alpha_lg_df = asl_alpha_df.append(lg_df, ignore_index = True)\n",
    "asl_alpha_lg_df.to_csv('./dataframes/asl_alpha_lg_df.csv')\n",
    "\n",
    "def save_data(arr, prefix):\n",
    "    np.savetxt('./train_test/{}/X_train.csv'.format(prefix), arr[0], delimiter=',')\n",
    "    np.savetxt('./train_test/{}/X_test.csv'.format(prefix), arr[1], delimiter=',')\n",
    "    np.savetxt('./train_test/{}/y_train.csv'.format(prefix), arr[2], delimiter=',', fmt='%s')\n",
    "    np.savetxt('./train_test/{}/y_test.csv'.format(prefix), arr[3], delimiter=',', fmt='%s')\n",
    "    print('saved data in ./train_test/{}'.format(prefix))\n",
    "\n",
    "# Base dataset - test split on alpha and digits asl data\n",
    "X = np.vstack(asl_alpha_digits_df['images'])\n",
    "y = asl_alpha_digits_df['label']\n",
    "X_train_ad, X_test_ad, y_train_ad, y_test_ad = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "save_data([X_train_ad, X_test_ad, y_train_ad, y_test_ad], 'base')\n",
    "\n",
    "\n",
    "# Combined dataset - test split on alpha asl + lg\n",
    "X_alpha_lg = np.vstack(asl_alpha_lg_df['images'])\n",
    "y_alpha_lg = asl_alpha_lg_df['label']\n",
    "X_train_alpha_lg, X_test_alpha_lg, y_train_alpha_lg, y_test_alpha_lg = train_test_split(X_alpha_lg, y_alpha_lg, test_size=0.25, random_state=0)\n",
    "save_data([X_train_alpha_lg, X_test_alpha_lg, y_train_alpha_lg, y_test_alpha_lg], 'combo')\n",
    "\n",
    "# Alpha train - lg test\n",
    "X_alpha_train = np.vstack(asl_alpha_df['images'])\n",
    "y_alpha_train = asl_alpha_df['label']\n",
    "X_lg_test = np.vstack(lg_df['images'])\n",
    "y_lg_test = lg_df['label']\n",
    "save_data([X_alpha_train, X_lg_test, y_alpha_train, y_lg_test], 'alphalg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "marine-emphasis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fig saved under ./previews/asl.jpg\n",
      "fig saved under ./previews/lg.jpg\n"
     ]
    }
   ],
   "source": [
    "gridsize = 5\n",
    "numfigs = gridsize**2\n",
    "figsize = (10, 10)\n",
    "cols = gridsize\n",
    "rows = gridsize\n",
    "\n",
    "def trim(axs, N):\n",
    "    axs = axs.flat\n",
    "    n = min(N, len(axs))\n",
    "    for ax in axs[n:]:\n",
    "        ax.remove()\n",
    "    return axs[:n]\n",
    "\n",
    "def printFigs(X, y, path):\n",
    "    plot, axs = plt.subplots(rows, cols, figsize=figsize)\n",
    "    axs = trim(axs, numfigs)\n",
    "    for ax, fig in zip(axs, range(0, (y.size - 1), math.floor((y.size - 1)/numfigs))):\n",
    "        sign = X[fig]\n",
    "        sign_pixels = sign.reshape(50, 50)\n",
    "        ax.imshow(sign_pixels)\n",
    "        ax.axis('off')\n",
    "        ax.set_title('label = {}'.format(y[fig]))\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "    print('fig saved under {}'.format(path))\n",
    "\n",
    "printFigs(X, y, './previews/asl.jpg')\n",
    "printFigs(X_lg_test, y_lg_test, './previews/lg.jpg')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "sorted-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "def generate_heatmap(logisticRegr, classes, prefix):\n",
    "    scale = np.max(np.abs(logisticRegr.coef_))\n",
    "    p = plt.figure(figsize=(15,15));\n",
    "    grid = ImageGrid(p, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(6, 6),\n",
    "                     axes_pad=0.25,\n",
    "                    )\n",
    "    nclasses = len(classes)\n",
    "    for ax, im in zip(grid, [i for i in range(nclasses)]):\n",
    "        ax.imshow(logisticRegr.coef_[im].reshape(50, 50),\n",
    "                      cmap=plt.cm.RdBu, vmin=-scale, vmax=scale);\n",
    "        ax.axis('off')\n",
    "        ax.set_title(classes[im])\n",
    "    plt.savefig('./heatmaps/{}.png'.format(prefix))\n",
    "    plt.close()\n",
    "\n",
    "def generate_classification_report(y_test, predictions, prefix):\n",
    "    print(\n",
    "        f\"Classification report for {prefix}:\\n\"\n",
    "        f\"{classification_report(y_test, predictions)}\\n\"\n",
    "    )\n",
    "\n",
    "def generate_confusion_matrix(y_test, predictions, classes, prefix):\n",
    "    array = confusion_matrix(y_test, predictions)\n",
    "    df_cm = pd.DataFrame(array, index = classes,\n",
    "                  columns = classes)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.savefig('./cmatrix/{}.png'.format(prefix))\n",
    "    plt.close()\n",
    "    \n",
    "def generate_heatmap_overlay(misclassifiedIndexes, test_lbl, test_img, predictions, logisticRegr, classes, prefix):\n",
    "    index = misclassifiedIndexes[10]\n",
    "    actual = test_lbl[index]\n",
    "    pred = predictions[index]\n",
    "    img_arr = test_img[index]\n",
    "    img = img_arr.reshape(50, 50)\n",
    "\n",
    "    mask = logisticRegr.coef_[classes.index(actual.upper())].reshape(50, 50);\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(mask, alpha=0.5, cmap=plt.cm.RdBu) #alpha sets transparency, cmap can choose color\n",
    "    plt.savefig('./heatmaps/overlay_{}_actual.png'.format(prefix))\n",
    "    plt.close()\n",
    "    \n",
    "    mask_2 = logisticRegr.coef_[classes.index(pred.upper())].reshape(50, 50);\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(mask_2, alpha=0.5, cmap=plt.cm.RdBu) #alpha sets transparency, cmap can choose color\n",
    "    plt.savefig('./heatmaps/overlay_{}_pred.png'.format(prefix))\n",
    "    plt.close()\n",
    "    \n",
    "def generate_misclassified_matrix(X_test, y_test, predictions, logisticRegr, classes, prefix):\n",
    "    index = 0\n",
    "    misclassifiedIndexes = []\n",
    "    for label, predict in zip(y_test, predictions):\n",
    "        if label != predict:\n",
    "            misclassifiedIndexes.append(index)\n",
    "        index +=1\n",
    "        \n",
    "    missedCount = len(misclassifiedIndexes)\n",
    "    print('Count of misclassified: {}, total test imgs: {}'.format(missedCount, len(predictions)))\n",
    "    print('Percent misclassified: {}%'.format(missedCount / len(predictions) * 100))\n",
    "    print('\\nFirst 25 misclassifications:')\n",
    "\n",
    "    test_img = np.array(X_test)\n",
    "    test_lbl = np.array(y_test)\n",
    "\n",
    "    plot, axs = plt.subplots(rows, cols, figsize=figsize)\n",
    "    axs = trim(axs, numfigs)\n",
    "    for ax, badindex in zip(axs, misclassifiedIndexes[0:25]):\n",
    "        digit = test_img[badindex]\n",
    "        digit_pixels = digit.reshape(50, 50)\n",
    "        ax.imshow(digit_pixels)\n",
    "        ax.axis('off')\n",
    "        ax.set_title('pre: {}, act: {}'.format(predictions[badindex], test_lbl[badindex]), fontsize = 15)\n",
    "    plt.savefig('./misclassified/{}.png'.format(prefix))\n",
    "    plt.close()\n",
    "    generate_heatmap_overlay(misclassifiedIndexes, test_lbl, test_img, predictions, logisticRegr, classes, prefix)\n",
    "\n",
    "def run_regression(X, X_test, y, y_test, classes, prefix):\n",
    "    logisticRegr = LogisticRegression(C=50/len(classes), penalty='l1', solver='saga', tol=0.1)\n",
    "    logisticRegr.fit(X, y)\n",
    "    predictions = logisticRegr.predict(X_test)\n",
    "    # show score to confirm success \n",
    "    score = logisticRegr.score(X_test, y_test)\n",
    "    scores[prefix] = score\n",
    "    print(prefix, score)\n",
    "    generate_heatmap(logisticRegr, classes, prefix)\n",
    "    generate_classification_report(y_test, predictions, prefix)\n",
    "    generate_confusion_matrix(y_test, predictions, classes, prefix)\n",
    "    generate_misclassified_matrix(X_test, y_test, predictions, logisticRegr, classes, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dangerous-roman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base 0.8934817170111288\n",
      "Classification report for base:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76        13\n",
      "           1       1.00      0.93      0.97        15\n",
      "           2       0.83      0.79      0.81        19\n",
      "           3       0.92      1.00      0.96        11\n",
      "           4       0.95      0.83      0.88        23\n",
      "           5       0.89      0.94      0.92        18\n",
      "           6       0.43      0.64      0.51        14\n",
      "           7       1.00      0.76      0.87        17\n",
      "           8       0.83      1.00      0.91        15\n",
      "           9       1.00      1.00      1.00        22\n",
      "           a       1.00      1.00      1.00        13\n",
      "           b       0.80      0.92      0.86        13\n",
      "           c       1.00      1.00      1.00        19\n",
      "           d       0.91      0.91      0.91        22\n",
      "           e       1.00      0.95      0.98        22\n",
      "           f       0.94      1.00      0.97        17\n",
      "           g       1.00      1.00      1.00        26\n",
      "           h       1.00      1.00      1.00        19\n",
      "           i       0.92      0.92      0.92        13\n",
      "           j       1.00      1.00      1.00        16\n",
      "           k       0.93      0.87      0.90        15\n",
      "           l       1.00      1.00      1.00        17\n",
      "           m       0.86      0.86      0.86        22\n",
      "           n       0.85      0.89      0.87        19\n",
      "           o       0.87      0.72      0.79        18\n",
      "           p       1.00      1.00      1.00        21\n",
      "           q       1.00      1.00      1.00        16\n",
      "           r       0.91      0.87      0.89        23\n",
      "           s       1.00      0.93      0.97        15\n",
      "           t       0.90      1.00      0.95         9\n",
      "           u       0.56      0.77      0.65        13\n",
      "           v       0.73      0.58      0.65        19\n",
      "           w       0.71      0.53      0.61        19\n",
      "           x       0.94      1.00      0.97        15\n",
      "           y       0.95      0.95      0.95        20\n",
      "           z       0.85      0.81      0.83        21\n",
      "\n",
      "    accuracy                           0.89       629\n",
      "   macro avg       0.89      0.90      0.89       629\n",
      "weighted avg       0.90      0.89      0.89       629\n",
      "\n",
      "\n",
      "Count of misclassified: 67, total test imgs: 629\n",
      "Percent misclassified: 10.651828298887123%\n",
      "\n",
      "First 25 misclassifications:\n"
     ]
    }
   ],
   "source": [
    "run_regression(X_train_ad, X_test_ad, y_train_ad, y_test_ad, all_classes, 'base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "latter-artist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo 0.9154013015184381\n",
      "Classification report for combo:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       1.00      0.82      0.90        22\n",
      "           b       0.86      1.00      0.92        12\n",
      "           c       1.00      0.88      0.94        26\n",
      "           d       0.95      0.95      0.95        20\n",
      "           e       0.96      0.96      0.96        27\n",
      "           f       1.00      0.95      0.97        19\n",
      "           g       0.88      0.93      0.90        15\n",
      "           h       1.00      0.82      0.90        11\n",
      "           i       0.96      1.00      0.98        22\n",
      "           j       0.94      0.94      0.94        18\n",
      "           k       0.94      0.94      0.94        18\n",
      "           l       0.95      0.95      0.95        20\n",
      "           m       0.62      1.00      0.76         8\n",
      "           n       1.00      0.68      0.81        22\n",
      "           o       0.86      1.00      0.92        18\n",
      "           p       0.95      1.00      0.97        19\n",
      "           q       1.00      0.94      0.97        18\n",
      "           r       0.96      0.96      0.96        24\n",
      "           s       0.72      0.90      0.80        20\n",
      "           t       0.75      0.79      0.77        19\n",
      "           u       0.81      0.93      0.87        14\n",
      "           v       0.89      0.67      0.76        12\n",
      "           w       0.88      1.00      0.93        14\n",
      "           x       1.00      0.94      0.97        17\n",
      "           y       1.00      0.92      0.96        12\n",
      "           z       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.92       461\n",
      "   macro avg       0.92      0.92      0.91       461\n",
      "weighted avg       0.93      0.92      0.92       461\n",
      "\n",
      "\n",
      "Count of misclassified: 39, total test imgs: 461\n",
      "Percent misclassified: 8.459869848156181%\n",
      "\n",
      "First 25 misclassifications:\n"
     ]
    }
   ],
   "source": [
    "run_regression(X_train_alpha_lg, X_test_alpha_lg, y_train_alpha_lg, y_test_alpha_lg, letter_classes, 'combo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dangerous-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lg 0.19230769230769232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for lg:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.00      0.00      0.00         1\n",
      "           b       0.00      0.00      0.00         1\n",
      "           c       0.00      0.00      0.00         1\n",
      "           d       0.00      0.00      0.00         1\n",
      "           e       0.00      0.00      0.00         1\n",
      "           f       0.00      0.00      0.00         1\n",
      "           g       0.00      0.00      0.00         1\n",
      "           h       0.00      0.00      0.00         1\n",
      "           i       0.00      0.00      0.00         1\n",
      "           j       0.00      0.00      0.00         1\n",
      "           k       0.00      0.00      0.00         1\n",
      "           l       0.50      1.00      0.67         1\n",
      "           m       0.00      0.00      0.00         1\n",
      "           n       0.00      0.00      0.00         1\n",
      "           o       0.00      0.00      0.00         1\n",
      "           p       0.00      0.00      0.00         1\n",
      "           q       0.00      0.00      0.00         1\n",
      "           r       0.00      0.00      0.00         1\n",
      "           s       0.00      0.00      0.00         1\n",
      "           t       0.00      0.00      0.00         1\n",
      "           u       0.25      1.00      0.40         1\n",
      "           v       0.50      1.00      0.67         1\n",
      "           w       0.00      0.00      0.00         1\n",
      "           x       0.00      0.00      0.00         1\n",
      "           y       0.25      1.00      0.40         1\n",
      "           z       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.19        26\n",
      "   macro avg       0.10      0.19      0.12        26\n",
      "weighted avg       0.10      0.19      0.12        26\n",
      "\n",
      "\n",
      "Count of misclassified: 21, total test imgs: 26\n",
      "Percent misclassified: 80.76923076923077%\n",
      "\n",
      "First 25 misclassifications:\n"
     ]
    }
   ],
   "source": [
    "run_regression(X_alpha_train, X_lg_test, y_alpha_train, y_lg_test, letter_classes, 'lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "royal-regulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base': 0.8934817170111288, 'combo': 0.9154013015184381, 'lg': 0.19230769230769232}\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-antarctica",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
